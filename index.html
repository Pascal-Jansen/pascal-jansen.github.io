<html lang="en-us" data-lt-installed="true">
    <head>
        <title>Pascal Jansen - Portfolio & Research</title>
        <meta property="og:title" content="Pascal Jansen - Portfolio & Research" />
        <meta property="og:type" content="website" />
        <meta property="og:image" content="https://pascal-jansen.github.io/assets/img/og-image.jpg" />
        <meta property="og:description" content="PhD Candidate and Research Associate at Ulm University focusing on human-in-the-loop optimization, adaptive user interfaces, and trust calibration for automated vehicles and extended reality." />
        <meta property="og:url" content="https://pascal-jansen.github.io/" />
        <meta name="description" content="Discover the work of Pascal Jansen, a PhD Candidate and Research Associate at Ulm University and Visiting Researcher at University College London, focused on HCI, Computational Modeling, and Inclusive Design for Ubiquitous Personalization." />
        <meta name="keywords" content="Pascal Jansen, Ulm University, University College London, HCI, Human-Computer Interaction, Computational Modeling, Inclusive Design, Ubiquitous Personalization, Mobility, Research, Portfolio" />
        <meta charset="utf-8" />
        <meta name="author" content="Pascal Jansen" />
        <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0" />

        <link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
        <link rel="stylesheet" type="text/css" href="css/animate.css" />
        <link rel="stylesheet" type="text/css" href="css/main.css" />
        <link rel="stylesheet" type="text/css" href="css/showcase.css" />
        <link rel="stylesheet" type="text/css" href="css/news.css" />
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css" />

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css"> 

        <!-- favicon -->
        <link rel="icon" href="images/favicon.ico">
        <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16.png">
        <!-- iOS / iPadOS home-screen icon -->
        <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">

        <script type="text/javascript" src="js/jquery.js"></script>
        <script type="text/javascript" src="js/scrollTo.js"></script>
        <script type="text/javascript" src="js/wow.js"></script>
        <script type="text/javascript" src="js/parallax.js"></script>
        <script type="text/javascript" src="js/headhesive.js"></script>
        <script type="text/javascript" src="js/main.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
    </head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N465H94Q6K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-N465H94Q6K');
</script>
    
    <body>

        <header class="banner">

            <div class="container">

                <div class="logo pull-left">
                    Pascal&nbsp;Jansen
                </div>

                <!-- Hamburger toggle (hidden on large screens) -->
                <input type="checkbox" id="nav-toggle" class="nav-toggle">
                <label for="nav-toggle" class="hamburger">
                <span></span><span></span><span></span>
                </label>

                <nav class="pull-right">
                <ul class="list-unstyled">
                    <li><a href="#aboutme">Profile</a></li>
                    <li><a href="#agenda">Research Agenda</a></li>
                    <li><a href="#news">News</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a target="_blank" href="data/CV_Jansen_2026.pdf">CV</a></li>
                    <li><a target="_blank" href="mailto:pascal.jansen@uni-ulm.de">E-Mail</a></li>
                </ul>
                </nav>

            </div>
        </header>

        <!-- Side profile panel (desktop only) -->
        <div id="side-profile-panel" class="side-profile-panel">

            <div class="side-profile-inner">

                <div class="text-center">
                    <h2>Pascal&nbsp;Jansen</h2>
                </div>

                <img src="images/uu-jansen-transparent.png"
                    alt="Profile Picture"
                    class="side-profile-img" />

                <div class="side-profile-text text-center">

                    <br/>

                    <div class="side-profile-email">
                        <a href="mailto:pascal.jansen@uni-ulm.de">pascal.jansen (at) uni-ulm.de</a>
                    </div>
                </div>

                <div class="side-profile-links text-center">
                    <button type="button" class="btn btn-secondary"
                        onclick="window.open('data/CV_Jansen_2026.pdf', '_blank')"
                        title="CV"
                        style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                            display:flex;align-items:center;justify-content:center;">
                        <!-- <i class="bi bi-file-earmark-person"></i> --> CV
                    </button>

                    <button type="button" class="btn btn-secondary"
                        onclick="window.open('https://scholar.google.de/citations?user=cR1_0-EAAAAJ&hl=en', '_blank')"
                        title="Google Scholar"
                        style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                            display:flex;align-items:center;justify-content:center;">
                        <img src="images/google-scholar.png"
                        alt="Google Scholar"
                        style="height:18px;width:auto;">
                    </button>

                    <button type="button" class="btn btn-secondary"
                        onclick="window.open('https://www.linkedin.com/in/pascal-jansen-/', '_blank')"
                        title="LinkedIn"
                        style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                            display:flex;align-items:center;justify-content:center;">
                        <i class="bi bi-linkedin"></i>
                    </button>

                    <button type="button" class="btn btn-secondary"
                        onclick="window.open('https://github.com/Pascal-Jansen', '_blank')"
                        title="GitHub"
                        style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                            display:flex;align-items:center;justify-content:center;">
                        <i class="bi bi-github"></i>
                    </button>
                </div>


                <div class="side-updates">
                <div class="side-updates-title" style="margin-top: 20px;">Current Affiliation</div>

                <div class="side-affiliation">
                    <img class="side-affil-logo" src="images/uni_ulm.png" alt="Ulm University logo">

                    <div class="side-affil-text">
                    <div class="side-affil-org">Ulm University</div>
                    <div class="side-affil-dept">Institute of Media Informatics</div>
                    <div class="side-affil-role">Research Associate &amp; PhD Candidate</div>
                    <div class="side-affil-dates">June, 2021 — Current</div>
                    </div>
                </div>

                <div class="side-affiliation">
                    <img class="side-affil-logo" src="images/zefwih.png" alt="Zefwih Games logo">

                    <div class="side-affil-text">
                    <div class="side-affil-org">Zefwih GbR</div>
                    <div class="side-affil-role">Co-Founder</div>
                    <div class="side-affil-dates">January, 2022 — Current</div>
                    </div>
                </div>
                </div>

                <div class="side-updates">
                <div class="side-updates-title" style="margin-top: 25px;">Previous Affiliation</div>

                <div class="side-affiliation">
                    <img class="side-affil-logo" src="images/ucl.png" alt="UCL logo">

                    <div class="side-affil-text">
                    <div class="side-affil-org">UCL Interaction Centre</div>
                    <div class="side-affil-dept">University College London</div>
                    <div class="side-affil-role">Visiting Researcher</div>
                    <div class="side-affil-dates">January, 2025 — March, 2025</div>
                    </div>
                </div>
                </div>


                <div class="side-updates">
                <div class="side-updates-title" style="margin-top: 25px;">Recent Updates</div>

                <div class="side-updates-list" role="list">

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2026-02</div>
                    <div class="side-update-text">
                        Senior Associate Chair, CHIWORK ’26
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2026-02</div>
                    <div class="side-update-text">
                        Joined the Best Paper Award Committee of CHI ’26
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2026-01</div>
                    <div class="side-update-text">
                        Three papers conditionally accepted, CHI ’26
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2026-01</div>
                    <div class="side-update-text">
                        Joined the Distinguished Reviewer Board of ACM TOCHI.
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-12</div>
                    <div class="side-update-text">
                        Student Research Competition Chair, MuC 2026.
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-12</div>
                    <div class="side-update-text">
                        Honorable Mention Award at MUM ’25
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-10</div>
                    <div class="side-update-text">
                        Paper accepted at MUM ’25
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-08</div>
                    <div class="side-update-text">
                        Associate Chair, CHI ’26 (User Experience & Usability)
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-08</div>
                    <div class="side-update-text">
                        Paper accepted at IEEE RO-MAN ’25
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-08</div>
                    <div class="side-update-text">
                        Released v1.1.0 of <em>Bayesian Optimization for Unity</em>
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-04</div>
                    <div class="side-update-text">
                        Honorable Mention Award at CHI ’25 (Yokohama)
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-03</div>
                    <div class="side-update-text">
                        Two papers published at HRI ’25
                    </div>
                    </div>

                    <div class="side-update" role="listitem">
                    <div class="side-update-date">2025-01</div>
                    <div class="side-update-text">
                        Visiting Researcher at UCL Interaction Centre (London)
                    </div>
                    </div>

                </div>
                </div>

            </div>
        </div>

        <!--  Bio Section  -->
        <section class="bio" id="bio" style="background-color: rgb(224 224 224); text-align: left; position: relative;">
            <div class="container">

                <!-- ========== DESKTOP / LARGE VIEW ========== -->
                <div class="row equal-height bio-desktop">
                <!-- Left column with text -->
                <div class="col-md-8 panel" style="background-color: #ffffff47; z-index: 100000">
                    <div class="caption">
                    <br />
                    <h1 style="margin-top: 0;">Pascal Jansen</h1>
                    </div>

                    <p>
                    <span>pascal.jansen (at) uni-ulm.de</span>
                    </p>
                    <br />
                    <p>
                    <span>PhD Candidate and Research Associate at 
                        <a target="_blank" href="https://www.uni-ulm.de/en/in/mi/institute/staff/pascal-jansen">Ulm University</a>, 
                        <br>Institute of Media Informatics, Human-Computer Interaction Group
                    </span><br><br>
                    <span>previously Visiting Researcher at 
                        <a target="_blank" href="https://www.ucl.ac.uk/uclic/">University College London, Interaction Centre</a>
                    </span>
                    </p>
                    <br />
                    <div class="agenda">


                        <div class="banner-links">
                            <!-- Banner links 
                             <button class="banner-about-toggle" type="button" aria-expanded="false">
                                <i class="bi bi-chevron-right"></i>
                                <span>About Me</span>
                            </button>-->

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('data/CV_Jansen_2026.pdf', '_blank')"
                                title="CV"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <!-- <i class="bi bi-file-earmark-person"></i> --> CV
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://scholar.google.de/citations?user=cR1_0-EAAAAJ&hl=en', '_blank')"
                                title="Google Scholar"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <img src="images/google-scholar.png"
                                alt="Google Scholar"
                                style="height:18px;width:auto;">
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://www.linkedin.com/in/pascal-jansen-/', '_blank')"
                                title="LinkedIn"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <i class="bi bi-linkedin"></i>
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://github.com/Pascal-Jansen', '_blank')"
                                title="GitHub"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <i class="bi bi-github"></i>
                            </button>
                        </div>


                        <div class="mission-block" id="mission">
                        <div class="mission-kicker"><span>Mission</span></div>

                            <h2 class="mission-tagline">Expanding What Humans Can Perceive, Decide, and Control</h2>

                            <div class="mission-subline">
                            From Closed Autonomy to Human-in-the-Loop in Future Mobility and XR Systems
                            </div>

                            <div class="mission-text">
                            <p>
                                As interactive systems increasingly automate perception, prediction, planning, and control, humans are often reduced to supervisors of system behavior they neither chose nor shaped.
                                This shift erodes agency and trust and limits how effectively people can benefit from automation—particularly in safety-critical and immersive domains such as automated mobility and extended reality (XR), where system decisions directly affect safety.
                            </p>
                            <p>
                                My research advances a <em>Human–Automation Centaur</em> perspective on human-technology interaction, in which machine intelligence augments human perception, decision-making, and action, while humans remain actively involved in shaping system goals, constraints, and responses.
                                By combining <strong>Human–Computer Interaction</strong>, <strong>inclusive design</strong>, and <strong>computational modeling</strong>, I design and empirically evaluate adaptive interfaces and human-in-the-loop optimization methods that make automated systems steerable.
                            </p>
                            </div>

                        </div>
                        <hr style="border: none; border-top: 1px solid #bfbfbf;">

                        <!-- Collapsible content 
                        <div class="banner-about-me is-collapsed">
                            <br>
                            <p>
                                I am a final-year PhD Candidate and Research Associate at
                                <a href="https://www.uni-ulm.de/en/in/mi/institute/staff/pascal-jansen" target="_blank" rel="noopener noreferrer">Ulm University</a>, Institute of Media Informatics,
                                affiliated with the Human–Computer Interaction (HCI) group and supervised by
                                <a href="https://www.uni-ulm.de/en/in/mi/institute/staff/enrico-rukzio" target="_blank" rel="noopener noreferrer">Enrico Rukzio</a>.
                                My work focuses on adaptive and personalized user interfaces for safety-critical and emerging contexts,
                                including automated vehicles and extended reality, using human-in-the-loop optimization and
                                simulation-based design methods.
                            </p>

                            <p>
                                I was a Visiting PhD Researcher at the
                                <a href="LINK_UCLIC" target="_blank" rel="noopener noreferrer">UCL Interaction Centre (UCLIC)</a>,
                                University College London, hosted by
                                <a href="LINK_MARK_COLLEY" target="_blank" rel="noopener noreferrer">Mark Colley</a>.
                                I received my M.Sc. (with distinction) from Ulm University, collaborating with
                                <a href="LINK_TERESA_HIRZLE" target="_blank" rel="noopener noreferrer">Teresa Hirzle</a>,
                                <a href="LINK_JAN_GUGENHEIMER" target="_blank" rel="noopener noreferrer">Jan Gugenheimer</a>, and
                                <a href="LINK_JULIAN_FROMMEL" target="_blank" rel="noopener noreferrer">Julian Frommel</a>.
                            </p>

                            <p>
                                My research has appeared at leading HCI venues including ACM CHI, TOCHI, IMWUT, and UIST, and has received
                                multiple recognitions, including
                                a <i class="bi bi-award"></i> CHI&nbsp;2025 Best Paper Honorable Mention,
                                a <i class="bi bi-award"></i> MUM&nbsp;2025 Best Paper Honorable Mention,
                                and a <i class="bi bi-trophy"></i> CHI&nbsp;PLAY&nbsp;2021 Audience Choice Award, and entrepreneurial recognitions including nomination for the
                                German Computer Game Awards and the Games for Change Awards.
                            </p>

                            <p>
                                I also contribute to the HCI community through associate chair roles (e.g., CHI, AutoUI), editorial and program committee service, and sustained peer reviewing.
                            </p>
                        </div>-->

                        <br/><br/><br/><br/>
                    </div>
                </div>

                <!-- Right column with large image -->
                <div class="col-md-4 align-bottom">
                    <img src="images/uu-jansen-transparent.png" alt="Profile Picture" class="profile-image" />
                </div>
                </div>

                <!-- ========== MOBILE / SMALL VIEW ========== -->
                <div class="bio-mobile">
                <!-- Top row: image beside name and contact -->
                <div class="row" style="align-items: center;">
                    
                    <div class="col-4 text-center" style="padding-top: 20px;">
                        <img src="images/uu-jansen-transparent.png"
                            alt="Profile Picture"
                            class="profile-image-mobile" />
                        </div>

                    <div class="col-8 text-center">
                        <div class="caption">
                            <br />
                            <h1 style="margin-top: 0; font-size: 28px;">Pascal Jansen</h1>
                        </div>
                        <p style="margin-bottom: 16px;">
                            <span>pascal.jansen (at) uni-ulm.de</span>
                        </p>
                        <p style="margin-bottom: 8px;">
                            <span>PhD Candidate and Research Associate at 
                            <a target="_blank" href="https://www.uni-ulm.de/en/in/mi/institute/staff/pascal-jansen">Ulm University</a>, 
                            Institute of Media Informatics, HCI Group
                            </span>
                        </p>
                        <p style="margin-bottom: 8px;">
                            <span>Previously Visiting Researcher at 
                            <a target="_blank" href="https://www.ucl.ac.uk/uclic/">University College London, Interaction Centre</a>
                            </span>
                        </p>
                    </div>

                </div>

                <!-- Second row: research text and buttons full-width -->
                <div class="row">
                    <div class="col-12">
                    <div class="agenda" style="margin-top: 10px;">

                        <div class="d-flex flex-wrap justify-content-center gap-2 banner-links" style="justify-content:center; align-items:center;">
                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('data/CV_Jansen_2026.pdf', '_blank')"
                                title="CV"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <!-- <i class="bi bi-file-earmark-person"></i> --> CV
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://scholar.google.de/citations?user=cR1_0-EAAAAJ&hl=en', '_blank')"
                                title="Google Scholar"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <img src="images/google-scholar.png"
                                alt="Google Scholar"
                                style="height:18px;width:auto;">
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://www.linkedin.com/in/pascal-jansen-/', '_blank')"
                                title="LinkedIn"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <i class="bi bi-linkedin"></i>
                            </button>

                            <button type="button" class="btn btn-secondary"
                                onclick="window.open('https://github.com/Pascal-Jansen', '_blank')"
                                title="GitHub"
                                style="width:42px;height:42px;border-radius:50%;padding:0;border:1px solid #ccc;
                                    display:flex;align-items:center;justify-content:center;">
                                <i class="bi bi-github"></i>
                            </button>
                        </div>

                        <br/>
                          <em style="display:block; color:#555; letter-spacing:0.08em; font-size:12px; margin-bottom:6px; text-align: center;">
                            — Mission —
                        </em>
                        <div class="bio-text-title">
                        <h2 style="font-size: 22px;text-align: center;">Human-Automation Centaurs for Expanding Human Capability</h2>
                        </div>
                        <p>
                        As interactive systems become increasingly autonomous, users are often reduced to supervising behavior they neither chose nor shaped.
                        This limits agency, trust, and the ability to benefit from what automation could actually enable—especially in safety-critical contexts such as automated mobility and immersive systems.
                        <br style="line-height:0.5"><br>
                        My research combining <strong>Human-Computer Interaction</strong>, <strong>Inclusive Design</strong>, and <strong>Computational Modeling</strong> explores how machine intelligence can expand what humans can perceive, decide, and control without displacing human judgment.
                        I adopt an <em>Automation Centaur</em> perspective, designing <em>steerable autonomy</em> in which humans and adaptive systems co-adapt through interaction.
                        </p>
                    </div>
                    </div>
                </div>
                </div>

            </div>
        </section>
        <!--  End Bio Section  -->

        <!-- Full-width floating quick links panel -->
        <div class="frosted-panel" id="header-links-panel" role="region" aria-label="Quick links panel" style="padding-top: 20; padding-bottom: 10;">
                <div class="container btn-group-wrapper">
                    <div class="col-md-12 btn-group" role="group" aria-label="Profile links" style="display: flex; justify-content: center;">

                                                                             
                                                <button type="button" class="btn btn-secondary" onclick="location.href='#aboutme'">
                                                    <h4>Profile</h4>
                                                </button>

                                                <button type="button" class="btn btn-secondary" onclick="location.href='#agenda'">
                                                    <h4>Research Agenda</h4>
                                                </button>

                                                <button type="button" class="btn btn-secondary" onclick="location.href='#news'">
                                                    <h4>News</h4>
                                                </button>
                                                
                                                <button type="button" class="btn btn-secondary" onclick="location.href='#publications'">
                                                    <h4>Publications</h4>
                                                </button>
                                                
                                                <button type="button" class="btn btn-secondary" onclick="location.href='#teaching'">
                                                    <h4>Teaching</h4>
                                                </button>                                   

                    </div>
                </div>
        </div>

<script>
(function () {
  const pairs = [
    { btn: '.banner-about-toggle', panel: '.banner-about-me', shiftImage: true },
    { btn: '.side-about-toggle',   panel: '.side-profile-about', shiftImage: false }
  ];

  pairs.forEach(({ btn, panel, shiftImage }) => {
    const b = document.querySelector(btn);
    const p = document.querySelector(panel);
    if (!b || !p) return;

    b.addEventListener('click', () => {
      const expanded = b.getAttribute('aria-expanded') === 'true';
      const opening = !expanded;

      b.setAttribute('aria-expanded', String(opening));
      p.classList.toggle('is-collapsed', expanded);

      if (shiftImage) {
        const bio = b.closest('.bio');
        if (!bio) return;

        if (opening) {
          // after the collapse class is removed, measure the expanded height
          requestAnimationFrame(() => {
            const h = p.scrollHeight; // content height
            bio.style.setProperty('--about-shift', (h + 16) + 'px'); // +16 for breathing room
          });
        } else {
          bio.style.setProperty('--about-shift', '0px');
        }
      }
    });
  });
})();
</script>






        <a target="_blank" id="showHere"></a>

        <!--  Publication Section  -->
        <section class="publication" id="publication">

            <div class="container" style="margin-top: 80px; margin-bottom: 50px;"> 
                <!-- Swiper HTML init -->
                <div class="swiper publication-swiper">
                  <div class="swiper-wrapper">

                    <!-- 0: MIRAGE (CHI '26) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://arxiv.org/abs/2601.19385"
                        style="background-image:url('images/mirage.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="164">
                        <source src="data/videos/mirage.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>MIRAGE: Enabling Real-Time Automotive Mediated Reality</h5>
                        <span>CHI ’26 (conditionally accepted)</span>
                    </div>
                    </div>

                    <!-- 1: Longitudinal Effects (TRF '25) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://www.sciencedirect.com/science/article/pii/S1369847825001779"
                        style="background-image:url('images/long-vis.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="10">
                        <source src="data/videos/long-vis-video.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>Longitudinal Effects of Visualizing Uncertainty of Situation Detection and Prediction of Automated Vehicles on User Perceptions</h5>
                        <span>TRF ’25</span>
                    </div>
                    </div>

                    <!-- 2: OptiCarVis (CHI '25) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/full/10.1145/3706598.3713514"
                        style="background-image:url('images/opticarvis.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="10">
                        <source src="data/videos/opticar-video-figure.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>OptiCarVis: Improving Automated Vehicle Functionality Visualizations Using Bayesian Optimization to Enhance User Experience</h5>
                        <span>CHI ’25</span>
                    </div>
                    </div>

                    <!-- 3: eHMI Bayesian Optimization (CHI '25) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/full/10.1145/3706598.3714187"
                        style="background-image:url('images/eHMI-BO.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="100">
                        <source src="data/videos/ehmi-video-figure.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>Improving External Communication of Automated Vehicles Using Bayesian Optimization</h5>
                        <span>CHI ’25</span>
                    </div>
                    </div>

                    <!-- 4: UAM BO (CHI '25) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/full/10.1145/3706598.3713288"
                        style="background-image:url('images/uam-BO.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="80">
                        <source src="data/videos/uam-bo-video-figure.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User Interface Design via Bayesian Optimization in Automated Urban Air Mobility Simulations</h5>
                        <span>CHI ’25</span>
                    </div>
                    </div>

                    <!-- 5: Bumpy Ride (CHI '25) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/10.1145/3706598.3714077"
                        style="background-image:url('images/bumpy-ride.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="9">
                        <source src="data/videos/bumpy_ride.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>Bumpy Ride? Understanding the Effects of External Forces on Spatial Interactions in Moving Vehicles</h5>
                        <span>CHI ’25</span>
                    </div>
                    </div>

                    <!-- 6: AutoVis (CHI '23) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/full/10.1145/3544548.3580760"
                        style="background-image:url('images/AutoVis.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="15">
                        <source src="data/videos/AutoVis.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>AutoVis: Enabling Mixed-Immersive Analysis of Automotive User Interface Interaction Studies</h5>
                        <span>CHI ’23</span>
                    </div>
                    </div>

                    <!-- 7: SwiVR-Car-Seat (IMWUT '21) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/abs/10.1145/3494968"
                        style="background-image:url('images/swivr-car-seat.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="10">
                        <source src="data/videos/swivr-car-seat.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>SwiVR-Car-Seat: Exploring Vehicle Motion Effects on Interaction Quality in Virtual Reality Automated Driving Using a Motorized Swivel Seat</h5>
                        <span>IMWUT ’21</span>
                    </div>
                    </div>

                    <!-- 8: ShARe (UIST '20) -->
                    <div class="swiper-slide carousel-cell"
                        data-link="https://dl.acm.org/doi/abs/10.1145/3379337.3415843"
                        style="background-image:url('images/share-small.png'); background-size:cover; background-position:center;">
                    <video class="preview-video" muted loop preload="metadata" data-start="10">
                        <source src="data/videos/shARe.mp4" type="video/mp4">
                    </video>
                    <div class="content">
                        <h5>ShARe: Enabling Co-Located Asymmetric Multi-User Interaction for Augmented Reality Head-Mounted Displays</h5>
                        <span>UIST ’20</span>
                    </div>
                    </div>
                  </div>
                  <div class="swiper-button-prev"></div>
                  <div class="swiper-button-next"></div>
                  <div class="swiper-pagination"></div>
                </div>


            <!-- Swiper initialization for Publications carousel -->
            <script>
let videoPlayTimeout = null;

let videoUnlocked = false;
window.addEventListener('pointerdown', () => {
  if (videoUnlocked) return;
  videoUnlocked = true;
  // Re-run state logic on first user interaction so play() is no longer blocked
  handleVideoState();
}, { once: true });

function startVideoFrom(video, startTime, slide) {
  // Reveal video layer (thumbnail stays as background underneath)
  slide.classList.add('video-on');

  const seekAndPlay = () => {
    try {
      // Clamp to duration if available to avoid invalid seeks
      const t = (Number.isFinite(video.duration) && video.duration > 0)
        ? Math.min(startTime, Math.max(0, video.duration - 0.25))
        : startTime;
      video.currentTime = t;
    } catch (e) {
      // ignore
    }

    video.play().catch(() => {
      // autoplay may still be blocked in some setups; ignore
    });
  };

  // If metadata is ready, we can seek immediately; otherwise wait.
  if (video.readyState >= 1) {
    seekAndPlay();
  } else {
    video.addEventListener('loadedmetadata', seekAndPlay, { once: true });
    // Force load in case the browser deferred it
    try { video.load(); } catch (e) {}
  }
}

function handleVideoState() {
  if (videoPlayTimeout) {
    clearTimeout(videoPlayTimeout);
    videoPlayTimeout = null;
  }

  // Stop everything and ensure thumbnails are visible (videos hidden)
  document.querySelectorAll('.publication-swiper .swiper-slide').forEach(slide => {
    slide.classList.remove('video-on');
    const v = slide.querySelector('video.preview-video');
    if (!v) return;
    v.pause();
    // Resetting currentTime can throw if metadata is not available yet (esp. Safari)
    try { v.currentTime = 0; } catch (e) {}
  });

  const activeSlide = document.querySelector('.publication-swiper .swiper-slide-active');
  if (!activeSlide) return;

  const video = activeSlide.querySelector('video.preview-video');
  if (!video) return;

  const startTime = parseFloat(video.dataset.start || '0');

  // Keep thumbnail visible for 3 seconds, then play video from data-start
  videoPlayTimeout = setTimeout(() => {
    const stillActive = document.querySelector('.publication-swiper .swiper-slide-active');
    if (!stillActive || stillActive !== activeSlide) return;

    startVideoFrom(video, startTime, activeSlide);
  }, 3000);
}

</script>
<script>
const pubSwiper = new Swiper('.publication-swiper', {
  loop: true,
  centeredSlides: true,
  slidesPerView: 'auto',
  spaceBetween: 16,
  slideToClickedSlide: true,
  navigation: { nextEl: '.swiper-button-next', prevEl: '.swiper-button-prev' },
  pagination: {
    el: '.swiper-pagination',
    clickable: true
  },
  on: {
    init: () => {
      // Ensure iOS/Safari allows inline playback
      document.querySelectorAll('.publication-swiper video.preview-video').forEach(v => {
        v.setAttribute('playsinline', '');
        v.playsInline = true;
        v.muted = true;
      });
      handleVideoState();
    },
    slideChangeTransitionEnd: handleVideoState,
    click: handleVideoState
  }
});
</script>
<script>
// Make only the active slide clickable
const swiperRoot = document.querySelector('.publication-swiper');

swiperRoot.addEventListener('click', (e) => {
  const activeSlide = swiperRoot.querySelector('.swiper-slide-active');
  if (!activeSlide) return;

  // Only react if the click happened inside the active slide
  if (!activeSlide.contains(e.target)) return;

  const link = activeSlide.getAttribute('data-link');
  if (!link) return;

  window.open(link, '_blank', 'noopener,noreferrer');
});
</script>
            </div>


            <div class="container">


                <hr>
                <h1 id="aboutme">Profile</h1>
                <div class="row">
                    <div class="col-md-12">
                        <p>
                        Pascal Jansen researches on <strong>human-in-the-loop design optimization</strong> for adaptive and trust-calibrated user interfaces in safety-critical and emerging contexts, including future mobility and extended reality. 
                        He is a final-year PhD Candidate and Research Associate at 
                        <a href="https://www.uni-ulm.de/en/in/mi/" target="_blank">Ulm University’s Institute of Media Informatics</a>, 
                        affiliated with the Human–Computer Interaction (HCI) group and supervised by 
                        <a href="https://www.uni-ulm.de/en/in/mi/institut/personal/er/" target="_blank">Enrico Rukzio</a>. 
                        His doctoral work develops a framework for computational user-centered optimization of human–vehicle interaction design, targeting reproducible, data-driven personalization of interactive systems. 
                        He leads the development of <strong>open-source research infrastructure</strong> that integrates computational methods, Unity-based simulators, and physiological sensing to enable scalable, reproducible interface optimization (e.g., 
                        <a href="https://github.com/Pascal-Jansen/Bayesian-Optimization-for-Unity" target="_blank">Bayesian-Optimization-for-Unity</a>).
                        Across these projects, he investigates steerable autonomy: interfaces that let users steer what the system optimizes and why, rather than only consuming automation outputs.
                        </p>

                        <p>
                        His work has been published at leading HCI venues including 
                        <a href="https://dl.acm.org/conference/chi" target="_blank">ACM CHI</a>, 
                        <a href="https://dl.acm.org/journal/tochi" target="_blank">TOCHI</a>, 
                        <a href="https://dl.acm.org/journal/imwut" target="_blank">IMWUT</a>, 
                        and 
                        <a href="https://dl.acm.org/conference/uist" target="_blank">UIST</a>, 
                        and has received multiple recognitions, including a 
                        <strong>CHI 2025 Best Paper Honorable Mention</strong>, 
                        a <strong>MUM 2025 Best Paper Honorable Mention</strong>, 
                        and the <strong>CHI PLAY 2021 Audience Choice Award</strong>. 
                        He has also received entrepreneurial recognitions, including a nomination for the 
                        <a href="https://deutscher-computerspielpreis.de/" target="_blank">German Computer Game Awards</a> 
                        and the 
                        <a href="https://gamesforchange.org/" target="_blank">Games for Change Awards</a>.
                        </p>

                        <p>
                        He was a Visiting PhD Researcher at the 
                        <a href="https://www.ucl.ac.uk/uclic/" target="_blank">UCL Interaction Centre</a>, 
                        University College London, hosted by 
                        <a href="https://m-colley.github.io/" target="_blank">Mark Colley</a>, 
                        and received his M.Sc. in Computer Science (with distinction) from 
                        <a href="https://www.uni-ulm.de/en/" target="_blank">Ulm University</a>. 
                        He contributes to the HCI community through associate chair roles (e.g., CHI, AutoUI), editorial and program committee service, and sustained peer reviewing, including multiple Outstanding Reviewer recognitions, and he currently serves on the Distinguished Reviewer Board of ACM TOCHI.
                        </p>

                        <p>
                        His research and entrepreneurial work has been supported by institutional and competitive funding, including programs of the German 
                        <a href="https://www.bundeswirtschaftsministerium.de/Redaktion/DE/Artikel/Wirtschaft/Games/strategie-games-standort-deutschland.html" target="_blank">Federal Ministry for Economic Affairs and Climate Action (BMWK)</a> 
                        and career development grants from 
                        <a href="https://www.uni-ulm.de/en/einrichtungen/resul/research-funding/early-career-programmes/" target="_blank">Ulm University</a>.
                        </p>

                        <p>
                        <strong>Research Keywords:</strong><br>
                        Human-in-the-Loop Optimization · Simulation-Based Design · Adaptive User Interfaces · Trust Calibration · Human-Centered AI · Future Mobility · Extended Reality
                        </p>
                    </div>
                </div>




                <hr>
                <h1 id="agenda">Research Agenda</h1>
                <div class="row">
                    <div class="col-md-12">
                        <p>
                            <strong style="color:rgb(138, 175, 192);">Ubiquitous User Interfaces</strong> are reshaping peoples' interaction with the world—from mixed-reality workspaces to autonomous cars, and service robots.
                            While many of these one-size-fits-all designs work for assumed <strong>average</strong> users, designs are <strong>not optimal for every individual</strong> when devices, tasks, environments, or user states sometimes radically shift (e.g., from daily smartphone use to one-time, unknown mixed-reality experience).
                            This exclusion disproportionately affects users with sensory, cognitive, or situational constraints, limiting their ability to benefit from emerging technologies.
                            My multidisciplinary research, therefore, bridges <strong>Human-Computer Interaction</strong>, <strong style="color:rgb(140, 181, 145);">Inclusive Design</strong>, and <strong style="color:rgb(244, 184, 152);">Computational Modeling</strong> to achieve three objectives (1-3):
                        </p>

                        <div class="venn-wrapper">
                        <div class="css-art--3-pie-venn-diagram">
                            <div class="css-art--pie css-art--pie-1">
                                <h3>Ubiquitous<br>User Interfaces</h3>
                                <ul>
                                <li><a href="https://dl.acm.org/doi/abs/10.1145/3379337.3415843" target="_blank">Mixed-Reality</a></li>
                                <li><a href="https://dl.acm.org/doi/abs/10.1145/3534617" target="_blank">Automated Vehicles</a></li>
                                <li><a href="https://dl.acm.org/doi/full/10.1145/3706598.3713288" target="_blank">Urban Air Mobility</a></li>
                                <li><a href="https://dl.acm.org/doi/10.1145/3706598.3713180" target="_blank">Human-Robot Interaction</a></li>
                                </ul>
                            </div>
                            <div class="pie-1-2-intersect">
                                <strong>(1) Accessible UIs<br>for everyone,<br>everywhere</strong>
                            </div>
                            <div class="css-art--pie css-art--pie-2">
                                <h3>Inclusive<br>Design</h3>
                                <ul>
                                <li><a href="https://dl.acm.org/doi/abs/10.1145/3492802" target="_blank">User State Assessment</a></li>
                                <li><a href="https://dl.acm.org/doi/10.1145/3643558" target="_blank">Sustainability</a></li>
                                <li><a href="https://www.sciencedirect.com/science/article/pii/S1369847824001141" target="_blank">Community Engagement</a></li>
                                <li><a href="https://dl.acm.org/doi/abs/10.1145/3383668.3419917" target="_blank">Serious Games & Education</a></li>
                                </ul>
                            </div>
                            <div class="pie-2-3-intersect">
                                <strong>(2) Models and simulations of the individual user</strong>
                            </div>
                            <div class="css-art--pie css-art--pie-3">
                                <h3>Computational<br>Modeling & Simulation</h3>    
                                <ul>
                                <li><a href="https://dl.acm.org/doi/10.1145/3706598.3713514" target="_blank">Human-in-the-Loop Bayesian Optimization</a></li>
                                <li><a href="https://ieeexplore.ieee.org/abstract/document/10974171" target="_blank">Simulation of Users</a></li>
                                <li><a href="https://dl.acm.org/doi/abs/10.1145/3494968" target="_blank">Novel Simulators</a></li>
                                </ul>
                            </div>
                            <div class="pie-3-1-intersect">
                                <strong>(3) Context-robust computational UI<br>design and interaction</strong>
                            </div>
                            <div class="pie-main-intersection">
                                Pascal Jansen
                            </div>
                        </div>
                        </div>

                        <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700,700i" rel="stylesheet">
                    
                        
                                <strong>(1) Accessible UIs for everyone, everywhere</strong>
                                <p>
                                    Addressing the exclusion of users with sensory, cognitive, or situational constraints by designing and evaluating software and hardware interfaces with appropriate interaction modalities.
                                </p>

                                <strong>(2) Models and simulations of the individual user</strong>
                                <p>
                                    Overcoming barriers of “average-user” design assumptions through data-driven models that capture demographic, cognitive, and motor diversity, enabling human-in-the-loop design optimization instead of resource-intensive traditional development cycles.
                                </p>

                                <strong>(3) Context-robust computational UI design and interaction</strong>
                                <p>
                                    Based on the developed systems and studies, I am dedicated to enable adaptive UIs that include individual users and are accessible in every context.
                                </p>

                                <p>This agenda operationalizes ‘human–automation centaurs’ as interactive loops where humans set goals/constraints and systems optimize/learn under transparency and safety constraints.</p>
                    </div>
                </div>






                <hr>
                <h1 id="news">News</h1>

                <div id="timeline" class="container">

                <!-- 2026 (top, visible) -->
                <div class="row year-row">
                    <div class="col-3 col-md-2 year-label">
                    <h4>2026</h4>
                    </div>
                    <div class="col-9 col-md-10 year-content">

                    <section class="event">
                        <h4>February</h4>
                        <ul>
                        <li>
                            Joined the Program Committe of <a href="https://chiwork.org/26/" target="_blank">CHIWORK '26</a> as Senior Member.
                        </li>
                        <li>
                            Joined the Best Paper Award Committe for <a href="https://chi2026.acm.org/" target="_blank">CHI '26</a>.
                        </li>
                        </ul>
                    </section>

                    <section class="event">
                        <h4>January</h4>
                        <ul>
                        <li>
                            At <a href="https://chi2026.acm.org/" target="_blank">CHI '26</a>, three papers led or co-authored were conditionally accepted, spanning mediated reality techniques in automotive settings and adaptive user interfaces for future mobility.
                        </li>
                        <li>
                            Joined the Distinguished Reviewer Board for <a href="https://dl.acm.org/journal/tochi" target="_blank">ACM Transactions on Computer-Human Interaction (TOCHI)</a>, which acknowledges sustained high-quality, timely, and constructive peer review contributions to the HCI community.
                        </li>
                        </ul>
                    </section>

                    </div>
                </div>

                <!-- 2025 (top, visible) -->
                <div class="row year-row">
                    <div class="col-3 col-md-2 year-label">
                    <h4>2025</h4>
                    </div>
                    <div class="col-9 col-md-10 year-content">

                    <section class="event">
                        <h4>December</h4>
                        <ul>
                        <li>
                            Joined the organizing committee of <a href="https://muc2026.mensch-und-computer.de/en/organizing-committee/" target="_blank">MuC 2026</a> as Student Research Competition Chair.
                        </li>
                        <li>
                            Received Honorable Mention Award at MUM 2025 for AirClick: Modularized Interactive Inflatables for On-Demand Room Transformation.
                        </li>
                        </ul>
                    </section>

                    <section class="event">
                        <h4>October</h4>
                        <ul>
                        <li>
                            Paper accepted at MUM 2025 –
                            <a href="https://doi.org/10.1145/3771882.3771888" target="_blank">AirClick: Modularized Interactive Inflatables for On-Demand Room Transformation</a>.
                        </li>
                        </ul>
                    </section>

                    <section class="event">
                        <h4>August</h4>
                        <ul>
                        <li>
                            Joined the CHI 2026 program committee as Associate Chair in the
                            <a href="https://chi2026.acm.org/authors/papers/selecting-a-subcommittee/" target="_blank">User Experience and Usability subcommittee</a>.
                        </li>
                        <li>
                            Paper accepted at <a href="https://www.ro-man2025.org/" target="_blank">IEEE RO-MAN 2025</a> (led by Maren Raab) –
                            <a href="https://arxiv.org/abs/2508.13699" target="_blank">Assessing Pedestrian Behavior Around Autonomous Cleaning Robots in Public Spaces: Findings from a Field Observation</a>.
                        </li>
                        <li>
                            Co-organized a workshop (<a href="https://dl.gi.de/bitstreams/4958bbfd-f90a-4976-af07-29c9d7ba85a9/download" target="_blank">Accessible Automated Automotive Workshop Series (A3WS): Accessibility in Mobility</a>)
                            and a tutorial (<a href="https://dl.gi.de/bitstreams/2a1f0b75-16e6-4810-8ef8-8713651fb79a/download" target="_blank">Human-in-the-Loop Bayesian Optimization for ALL: Practical Applications in Human-Computer Interaction Challenges</a>) at MuC 2025 in Chemnitz, Germany.
                        </li>
                        <li>
                            Released v1.1.0 of <a href="https://github.com/Pascal-Jansen/Bayesian-Optimization-for-Unity" target="_blank">Bayesian Optimization for Unity</a>, enabling a streamlined HITL workflow with Bayesian optimization (via BoTorch) to personalize designs.
                        </li>
                        </ul>
                    </section>

                    </div>
                </div>

                <!-- Hidden extra entries -->
                <div id="moreNews" style="display:none;">

                    <!-- 2025 (older) -->
                    <div class="row year-row">

                    <div class="col-3 col-md-2 year-label">
                    <h4></h4>
                    </div>

                    <div class="col-9 col-md-10 year-content">

                        <section class="event">
                            <h4>May</h4>
                            <ul>
                            <li>
                                At the <a href="https://www.uni-ulm.de/en/in/faculty-of-engineering-computer-science-and-psychology/in-detailseiten/news-detail/article/langer-abend-der-wissenschaft-2025/" target="_blank">Long Evening of Science at Ulm University</a>,
                                presented novel human-vehicle interaction research to more than 2,000 visitors, including prospective students and families.
                            </li>
                            <li>
                                Transportation Research Part F paper accepted:
                                <a href="https://www.sciencedirect.com/science/article/pii/S1369847825001779" target="_blank">
                                Longitudinal Effects of Visualizing Uncertainty of Situation Detection and Prediction of Automated Vehicles (AVs) on User Perceptions
                                </a>.
                                A three-day study with 50 participants viewing real-world commute videos twice daily showed that clear, consistent AV uncertainty visualizations significantly increased trust over time while revealing the need for explicit AV intent cues and manual intervention options.
                            </li>
                            </ul>
                        </section>

                        <section class="event">
                            <h4>April</h4>
                            <ul>
                            <li>
                                <a href="https://dl.acm.org/doi/full/10.1145/3706598.3713514" target="_blank">OptiCarVis</a> received an Honorable Mention Award at
                                <a href="https://chi2025.acm.org/" target="_blank">CHI ’25 in Yokohama, Japan</a>.
                            </li>
                            <li>
                                At CHI ’25, five papers led or co-authored were published, spanning sustainability, the impact of motion on interaction quality, and adaptive user interfaces for future mobility.
                            </li>
                            <li>
                                Delivered the laudatio for <a href="https://scholar.google.de/citations?user=Kt5I7wYAAAAJ&hl=en&oi=ao" target="_blank">Mark Colley</a> at the
                                <a href="https://sigchi.org/" target="_blank">SIGCHI</a> Awards Dinner, honoring his Special Recognition for Early Career Researcher Award.
                            </li>
                            </ul>
                        </section>

                        <section class="event">
                            <h4>March</h4>
                            <ul>
                            <li>
                                Two papers published at HRI ’25 in Melbourne, Australia:
                                <a href="https://ieeexplore.ieee.org/abstract/document/10974171" target="_blank">HUD-SUMO</a>, linking SUMO and CARLA to simulate AR HUD settings and predict their impact on reaction time, speed adherence, lane changes, and acceleration;
                                and <a href="https://ieeexplore.ieee.org/abstract/document/10973993" target="_blank">UAM-SUMO</a>, extending SUMO to model urban air taxi corridors alongside ground vehicles for large-scale studies of traffic flow, mode choice, and passenger trust.
                            </li>
                            </ul>
                        </section>

                        <section class="event">
                        <h4>February</h4>
                        <ul>
                            <li>
                            At the <a href="https://www.instagram.com/p/DGVPcRkIMKA/?img_index=3" target="_blank">Bildungsmesse Ulm 2025</a>, the VeMoR simulator attracted many prospective students
                            interested in high-immersion motion feedback in a safe, lab environment. The speaker of the Baden-Württemberg parliament and Ulm’s Mayor visited the booth.
                            </li>
                        </ul>
                        </section>

                        <section class="event">
                        <h4>January</h4>
                        <ul>
                            <li>
                            Started as a visiting researcher at the <a href="https://www.ucl.ac.uk/uclic/" target="_blank">UCL Interaction Centre</a> in London, UK, hosted by
                            <a href="https://scholar.google.de/citations?user=Kt5I7wYAAAAJ&hl=en&oi=ao" target="_blank">Mark Colley</a>.
                            </li>
                        </ul>
                        </section>

                    </div>
                    </div>

                    <!-- 2024 -->
                    <div class="row year-row">
                    <div class="col-3 col-md-2 year-label">
                        <h4>2024</h4>
                    </div>
                    <div class="col-9 col-md-10 year-content">

                        <section class="event">
                        <h4>June</h4>
                        <ul>
                            <li>
                            At the <a href="https://www.uni-ulm.de/universitaet/hochschulkommunikation/veranstaltungen/langer-abend-der-wissenschaft/" target="_blank">Long Evening of Science Fair at Ulm University</a>,
                            showcased VeMoR, a VR vehicle-motion simulator enabling roll, pitch, and yaw synchronization to the virtual vehicle to bridge the gap between static lab setups and expensive full-motion rigs.
                            Presented future mobility research to over 2,000 visitors.
                            </li>
                        </ul>
                        </section>

                        <section class="event">
                        <h4>May</h4>
                        <ul>
                            <li>
                            Transportation Research Part F paper accepted:
                            <a href="https://www.sciencedirect.com/science/article/pii/S1369847824001141" target="_blank">
                                Visualizing Imperfect Situation Detection and Prediction in Automated Vehicles: Understanding Users’ Perceptions via User-Chosen Scenarios
                            </a>.
                            EduLicit, a web-based platform, elicits public “challenging AV scenarios” and evaluates how visualizing an AV’s perception, prediction, and planning influences user acceptance.
                            </li>
                        </ul>
                        </section>

                        <section class="event">
                        <h4>January</h4>
                        <ul>
                            <li>
                            <a href="https://store.steampowered.com/app/2746510/The_Social_Engineer/" target="_blank">The Social Engineer</a> launched on Steam – a room-scale VR serious game for practicing social-engineering defense strategies.
                            </li>
                            <li>
                            <a href="https://dl.acm.org/doi/abs/10.1145/3610977.3637478" target="_blank">PedSUMO</a> accepted at HRI ’24, a SUMO extension simulating pedestrian interactions at unsignalized crossings to study how external AV signals affect large-scale pedestrian compliance (code on
                            <a href="https://github.com/M-Colley/pedsumo" target="_blank">GitHub</a>).
                            </li>
                        </ul>
                        </section>

                    </div>
                    </div>

                    <!-- 2023 -->
                    <div class="row year-row">
                    <div class="col-3 col-md-2 year-label">
                        <h4>2023</h4>
                    </div>
                    <div class="col-9 col-md-10 year-content">

                        <section class="event">
                        <h4>September</h4>
                        <ul>
                            <li>
                            <a href="https://www.auto-ui.org/23/organizers/" target="_blank">Registration Chair</a> at AutoUI ’23 in Ingolstadt, overseeing online and on-site registration and coordinating with ACM on organization and budgeting.
                            </li>
                        </ul>
                        </section>

                        <section class="event">
                        <h4>April</h4>
                        <ul>
                            <li>
                            First-author CHI ’23 paper:
                            <a href="https://dl.acm.org/doi/full/10.1145/3544548.3580760" target="_blank">AutoVis: Enabling Mixed-Immersive Analysis of Automotive UI Interaction Studies</a>.
                            AutoVis combines desktop and VR views with automotive-specific visualizations (context portals, driving-path events, avatars, trajectories, heatmaps), guided by expert requirements and validated on real and public datasets
                            (<a href="https://autovis-demo.onrender.com/" target="_blank">demo</a>).
                            </li>
                        </ul>
                        </section>

                    </div>
                    </div>

                </div> <!-- /#moreNews -->

                <div class="text-end pe-3">
                    <button id="moreBtn" class="btn btn-secondary">More News</button>
                </div>

                </div> <!-- /#timeline -->

                <script>
                let scrollPosBeforeExpand = null;
                let t = null;

                const btn = document.getElementById('moreBtn');
                const extra = document.getElementById('moreNews');

                btn.addEventListener('click', () => {
                const opening = !extra.classList.contains('is-open');

                if (opening) {
                    scrollPosBeforeExpand = window.scrollY;

                    // ensure element participates in layout first
                    extra.style.display = 'block';
                    requestAnimationFrame(() => {
                    extra.classList.add('is-open'); // triggers opacity/transform transition
                    });

                    btn.textContent = 'Show Less';
                } else {
                    extra.classList.remove('is-open'); // triggers fade-out
                    btn.textContent = 'More News';

                    const onEnd = (e) => {
                    if (e.propertyName !== 'opacity') return;
                    extra.removeEventListener('transitionend', onEnd);
                    extra.style.display = 'none'; // only after fade-out finishes
                    if (scrollPosBeforeExpand != null) {
                        window.scrollTo({ top: scrollPosBeforeExpand, behavior: 'smooth' });
                    }
                    };
                    extra.addEventListener('transitionend', onEnd);
                }
                });
                </script>







                <hr>
                <h1 id="publications">Publications (Excerpt)</h1>

                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/mirage.png" alt="MIRAGE preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="164">
                                <source src="data/videos/mirage.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>MIRAGE: Enabling Real-Time Automotive Mediated Reality</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen*</a></u>, Julian Britten*, Mark Colley*, Markus Sasalovici, and Enrico Rukzio (<i>*joint first-author</i>)
                        </p>
                        
                        <p><strong>CHI '26</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (conditionally accepted)</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-23')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/mirage.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/mirage.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://arxiv.org/pdf/2601.19385">arXiv</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-23" style="display: none; padding-top: 5px; text-align: justify;">
                            Traffic is inherently dangerous, with around 1.19 million fatalities annually. Automotive Mediated Reality (AMR) can enhance driving safety by overlaying critical information (e.g., outlines, icons, text) on key objects to improve awareness, altering objects' appearance to simplify traffic situations, and diminishing their appearance to minimize distractions. However, real-world AMR evaluation remains limited due to technical challenges. To fill this sim-to-real gap, we present MIRAGE, an open-source tool that enables real-time AMR in real vehicles. MIRAGE implements 15 effects across the AMR spectrum of augmented, diminished, and modified reality using state-of-the-art computational models for object detection and segmentation, depth estimation, and inpainting. In an on-road expert user study (N=9) of MIRAGE, participants enjoyed the AMR experience while pointing out technical limitations and identifying use cases for AMR. We discuss these results in relation to prior work and outline implications for AMR ethics and interaction design.    
                        </p>
                    </div>
                </div>

                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/provoice.png" alt="ProVoice preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="20">
                                <source src="data/videos/provoice.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>ProVoice: Designing Proactive Functionality for In-Vehicle Conversational Assistants using Multi-Objective Bayesian Optimization to Enhance Driver Experience</h2>
                        
                        <p> 
                            Josh Susak, Yifu Liu, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, and Mark Colley
                        </p>
                        
                        <p><strong>CHI '26</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (conditionally accepted)</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-22')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/provoice.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/provoice.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://arxiv.org/abs/2601.19421">arXiv</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-22" style="display: none; padding-top: 5px; text-align: justify;">
                            The next step for In-vehicle Conversational Assistants (IVCAs) will be their capability to initiate and automate proactive system interactions throughout journeys. However, diverse drivers make it challenging to design voice interventions tailored towards individual on-road expectations. This paper evaluates the effectiveness of Human-in-the-Loop (HITL) Multi-Objective Bayesian Optimization (MOBO) in design by implementing ProVoice: a Virtual Reality (VR) driving simulator integrating MOBO to investigate the effects of IVCA design variants on perceived mental demand, predictability, and usefulness. By reporting the Pareto Front from a within-subjects VR study (N=19), this paper proposes optimal design trade-offs. Follow-up analysis demonstrates MOBO's success in discovering effective intervention strategies, with reduced participant mental demand, alongside enhanced predictability and usefulness while engaging with the proactive IVCA. Implications for computational techniques in future research on proactive intervention strategies are discussed. ProVoice can extend to include alternative design parameters and driving scenarios, encouraging intervention design on a broad scale.    
                        </p>
                    </div>
                </div>

                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/ehmi4all.png" alt="eHMI for All preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="190">
                                <source src="data/videos/ehmi4all.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>eHMI for All - Investigating the Effect of External Communication of Automated Vehicles on Pedestrians, Manual Drivers, and Cyclists in Virtual Reality</h2>
                        
                        <p> 
                            Mark Colley, Simon Kopp, Debargha Dey, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, and Enrico Rukzio
                        </p>
                        
                        <p><strong>CHI '26</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (conditionally accepted)</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-21')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/ehmi4all.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/ehmi4all.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://arxiv.org/abs/2601.19440">arXiv</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-21" style="display: none; padding-top: 5px; text-align: justify;">
                            With automated vehicles (AVs), the absence of a human operator could necessitate external Human-Machine Interfaces (eHMIs) to communicate with other road users. Existing research primarily focuses on pedestrian-AV interactions, with limited attention given to other road users, such as cyclists and drivers of manually driven vehicles. So far, no studies have compared the effects of eHMIs across these three road user roles. Therefore, we conducted a within-subjects virtual reality experiment (N=40), evaluating the subjective and objective impact of an eHMI communicating the AV's intention to pedestrians, cyclists, and drivers under various levels of distraction (no distraction, visual noise, interference). eHMIs positively influenced safety perceptions, trust, perceived usefulness, and mental demand across all roles. While distraction and road user roles showed significant main effects, interaction effects were only observed in perceived usability. Thus, a unified eHMI design is effective, facilitating the standardization and broader adoption of eHMIs in diverse traffic.    
                        </p>
                    </div>
                </div>
           
                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/long-vis.png" alt="Longitudinal Effects preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/long-vis-video.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>Longitudinal Effects of Visualizing Uncertainty of Situation Detection and Prediction of Automated Vehicles on User Perceptions</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen*</a></u>, Mark Colley*, Max Rädler*, Jonas Schwedler, and Enrico Rukzio (<i>*joint first-author</i>)
                        </p>
                        
                        <p><strong>TRF '25</strong>: Transportation Research Part F: Psychology and Behavior</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-20')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/longitudinal-visualization.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/long-vis-video.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1369847825001779">Elsevier</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-20" style="display: none; padding-top: 5px; text-align: justify;">
                            This paper explores the impact of uncertainty visualizations in automated vehicle (AV) functionality on user perceptions over a three-day longitudinal study. Participants (N=50) watched real-world driving videos twice daily, in the morning and evening. These videos depicted morning and evening commutes, featuring visualizations of AVs' pedestrian detection, vehicle recognition, and pedestrian intention prediction. We measured perceived safety, trust, mental workload, and cognitive load using a within-subjects design. Results show increased perceived safety and trust over time, with higher ratings in the evening sessions, reflecting greater predictability and user confidence in AV by the study's end. However, inconsistencies in pedestrian detection and intention prediction led to mixed reactions, highlighting the need for visualization stability and clarity refinement. Participants also desired a feature indicating the AV's intended path and options for manual intervention. Our findings suggest transparency and usability in AV visualizations can foster trust and perceived safety, informing future AV interface design.
                        </p>
                    </div>
                </div>

                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/opticarvis.png" alt="OptiCarVis preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/opticar-video-figure.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>OptiCarVis: Improving Automated Vehicle Functionality Visualizations Using Bayesian Optimization to Enhance User Experience</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen*</a></u>, Mark Colley*, Svenja Krauß, Daniel Hirschle, and Enrico Rukzio (<i>*joint first-author</i>)
                        </p>

                        <!-- Conference Name with Custom Badge Behind -->
                        <div style="position: relative; display: inline-block;">
                            <p style="position: relative; z-index: 2; margin: 0;">
                            <strong>CHI '25</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems<b><div class="award">Honorable Mention Award</div></b>
                            </p>
                        </div>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-18')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/CHI25_OptiCarVis.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/opticar-video-figure.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/full/10.1145/3706598.3713514" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-18" style="display: none; padding-top: 5px; text-align: justify;">
                            Automated vehicle (AV) acceptance relies on their understanding via feedback. While visualizations aim to enhance user understanding of AV's detection, prediction, and planning functionalities, establishing an optimal design is challenging. Traditional "one-size-fits-all" designs might be unsuitable, stemming from resource-intensive empirical evaluations. This paper introduces OptiCarVis, a set of Human-in-the-Loop (HITL) approaches using Multi-Objective Bayesian Optimization (MOBO) to optimize AV feedback visualizations. We compare conditions using eight expert and user-customized designs for a Warm-Start HITL MOBO. An online study (N=117) demonstrates OptiCarVis's efficacy in significantly improving trust, acceptance, perceived safety, and predictability without increasing cognitive load. OptiCarVis facilitates a comprehensive design space exploration, enhancing in-vehicle interfaces for optimal passenger experiences and broader applicability.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/eHMI-BO.png" alt="eHMI BO preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="100">
                                <source src="data/videos/ehmi-video-figure.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>Improving External Communication of Automated Vehicles Using Bayesian Optimization</h2>
                        
                        <p> 
                            Mark Colley*, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen*</a></u>, Mugdha Keskar, and Enrico Rukzio (<i>*joint first-author</i>)
                        </p>
                        
                        <p><strong>CHI '25</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-17')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/CHI25_eHMI_BO.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/ehmi-video-figure.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/full/10.1145/3706598.3714187" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-17" style="display: none; padding-top: 5px; text-align: justify;">
                            The absence of a human operator in automated vehicles (AVs) may require external Human-Machine Interfaces (eHMIs) to facilitate communication with other road users in uncertain scenarios, for example, regarding the right of way.
                            Given the plethora of adjustable parameters, balancing visual and auditory elements is crucial for effective communication with other road users. With N=37 participants, this study employed multi-objective Bayesian optimization to enhance eHMI designs and improve trust, safety perception, and mental demand. By reporting the Pareto front, we identify optimal design trade-offs. This research contributes to the ongoing standardization efforts of eHMIs, supporting broader adoption.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/uam-BO.png" alt="UAM BO preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="80">
                                <source src="data/videos/uam-bo-video-figure.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User Interface Design via Bayesian Optimization in Automated Urban Air Mobility Simulations</h2>
                        
                        <p> 
                            Luca-Maxim Meinhardt, Clara Schramm, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Mark Colley, and Enrico Rukzio
                        </p>
                        
                        <p><strong>CHI '25</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-16')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/CHI2025___UAM_BO.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/uam-bo-video-figure.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/full/10.1145/3706598.3713288" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-16" style="display: none; padding-top: 5px; text-align: justify;">
                            Automated Urban Air Mobility (UAM) can improve passenger transportation and reduce congestion, but its success depends on passenger trust. While initial research addresses passengers' information needs, questions remain about how to simulate air taxi flights and how these simulations impact users and interface requirements.
                            We conducted a between-subjects study (N=40), examining the influence of motion fidelity in Virtual-Reality-simulated air taxi flights on user effects and interface design. Our study compared simulations with and without motion cues using a 3-Degrees-of-Freedom motion chair. Optimizing the interface design across six objectives, such as trust and mental demand, we used multi-objective Bayesian optimization to determine the most effective design trade-offs.
                            Our results indicate that motion fidelity decreases users' trust, understanding, and acceptance, highlighting the need to consider motion fidelity in future UAM studies to approach realism. However, minimal evidence was found for differences or equality in the optimized interface designs, suggesting personalized interface designs.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/bumpy-ride.png" alt="Bumpy Ride preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/bumpy_ride.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>Bumpy Ride? Understanding the Effects of External Forces on Spatial Interactions in Moving Vehicles</h2>
                        
                        <p> 
                            Markus Sasalovici, Albin Zeqiri, Robin Connor Schramm, Oscar Javier Ariza Nuñez, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Jann Philipp Freiwald, Mark Colley, Christian Winkler, and Enrico Rukzio
                        </p>
                        
                        <p><strong>CHI '25</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-15')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/bumpy_ride.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/bumpy_ride.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/10.1145/3706598.3714077" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-15" style="display: none; padding-top: 5px; text-align: justify;">
                            As the use of Head-Mounted Displays in moving vehicles increases, passengers can immerse themselves in visual experiences independent of their physical environment. However, interaction methods are susceptible to physical motion, leading to input errors and reduced task performance. This work investigates the impact of Gforces, vibrations, and unpredictable maneuvers on 3D interaction
                            methods. We conducted a field study with 24 participants in both stationary and moving vehicles to examine the effects of vehicle motion on four interaction methods: (1) Gaze&Pinch, (2) DirectTouch,
                            (3) Handray, and (4) HeadGaze. Participants performed selections in a Fitts’ Law task. Our findings reveal a significant effect of vehicle motion on interaction accuracy and duration across the tested combinations of Interaction Method × Road Type × Curve Type. We
                            found a significant impact of movement on throughput, error rate, and perceived workload. Finally, we propose future research considerations and recommendations on interaction methods during vehicle movement.    
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/plantpal.jpg" alt="PlantPal preview" />
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>PlantPal: Leveraging Precision Agriculture Robots to Facilitate Remote Engagement in Urban Gardening</h2>
                        
                        <p> 
                            Albin Zeqiri, Julian Britten, Clara Schramm, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Michael Rietzler, and Enrico Rukzio
                        </p>
                        
                        <p><strong>CHI '25</strong>: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-14')" class="abstract-btn">Abstract</button>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-14" style="display: none; padding-top: 5px; text-align: justify;">
                            Urban gardening is widely recognized for its numerous health and environmental benefits. However, the lack of suitable garden spaces, demanding daily schedules, and limited gardening expertise present major roadblocks for citizens looking to engage in urban gardening. While prior research has explored smart home solutions to support urban gardeners, these approaches currently do not fully address these practical barriers. In this paper, we present PlantPal, a system that enables the cultivation of garden spaces irrespective of one's location, expertise level, or time constraints. PlantPal enables the shared operation of a precision agriculture robot (PAR) that is equipped with garden tools and a multi-camera system. Insights from a 3-week deployment (N=18) indicate that PlantPal facilitated the integration of gardening tasks into daily routines, fostered a sense of connection with one's field, and provided an engaging experience despite the remote setting. We contribute design considerations for future robot-assisted urban gardening concepts.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/edulicit.png" alt="EduLicit preview" />
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>Visualizing Imperfect Situation Detection and Prediction in Automated Vehicles: Understanding Users’ Perceptions via User-Chosen Scenarios</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen*</a></u>, Mark Colley*, Tim Pfeifer, and Enrico Rukzio (<i>*joint first-author</i>)
                        </p>
                        
                        <p><strong>TRF '24</strong>: Transportation Research Part F: Psychology and Behavior</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-13')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/edulicit.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1369847824001141">Elsevier</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-13" style="display: none; padding-top: 5px; text-align: justify;">
                            User acceptance is essential for successfully introducing automated vehicles (AVs). Understanding the technology is necessary to overcome skepticism and achieve acceptance. This could be achieved by visualizing (uncertainties of) AV's internal processes, including situation perception, prediction, and trajectory planning. At the same time, relevant scenarios for communicating the functionalities are unclear. Therefore, we developed EduLicitto concurrently elicit relevant scenarios and evaluate the effects of visualizing AV's internal processes. A website capable of showing annotated videos enabled this methodology. With it, we replicated the results of a previous online study (N=76) using pre-recorded real-world videos. Additionally, in a second online study (N=22), participants uploaded scenarios they deemed challenging for AVs using our website. Most scenarios included large intersections and/or multiple vulnerable road users. Our work helps assess scenarios perceived as challenging for AVs by the public and, simultaneously, can help educate the public about visualizations of the functionalities of current AVs.
                        </p>
                    </div>
                </div>



                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/ped-sumo.png" alt="PedSUMO preview" />
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>PedSUMO: Simulacra of Automated Vehicle-Pedestrian Interaction Using SUMO To Study Large-Scale Effects</h2>
                        
                        <p> 
                            Mark Colley, Julian Czymmeck, Mustafa Kücükkocak, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, and Enrico Rukzio
                        </p>
                        
                        <p><strong>HRI '24</strong>: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-12')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/ped-sumo.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3610977.3637478" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-12" style="display: none; padding-top: 5px; text-align: justify;">
                            As automated vehicles become more widespread but lack a driver to communicate in uncertain situations, external communication, for example, via LEDs or displays, is evaluated. However, the concepts are mostly evaluated in simple scenarios, such as one person trying to cross in front of one automated vehicle. The traditional empirical approach fails to study the large-scale effects of these in this not-yet-real scenario. Therefore, we built PedSUMO, an enhancement to SUMO for the simulacra of automated vehicles' effects on public traffic, specifically how pedestrian attributes affect their respect for automated vehicle priority at unprioritized crossings. We explain the algorithms used and the derived parameters relevant to the crossing. We open-source our code under https://github.com/M-Colley/pedsumo and demonstrate an initial data collection and analysis of Ingolstadt, Germany.
                        </p>
                    </div>
                </div>



                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/esfs.png" alt="ESFs preview" />
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>'Eco Is Just Marketing': Unraveling Everyday Barriers to the Adoption of Energy-Saving Features in Major Home Appliances</h2>
                        
                        <p> 
                            Albin Zeqiri, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Jan Ole Rixen, Michael Rietzler, and Enrico Rukzio
                        </p>
                        
                        <p><strong>IMWUT '24</strong>: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-11')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/esfs.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3643558" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-11" style="display: none; padding-top: 5px; text-align: justify;">
                            Energy-saving features (ESFs) represent a simple way to reduce the resource consumption of home appliances (HAs), yet they remain under-utilized. While prior research focused on increasing the use of ESFs through behavior change interventions, there is currently no clarity on the barriers that restrict their utilization in the first place. To bridge this gap, we conducted a qualitative analysis of 349 Amazon product reviews and 98 Reddit discussions, yielding three qualitative themes that showcase how users perceive, interact with, and evaluate ESFs in HAs. Based on these themes, we derived frequent barriers to ESF adoption, which guided a subsequent expert focus group (N=5) to assess the suitability of behavior change interventions and potential alternative strategies for ESF adoption. Our findings deepen the understanding of everyday barriers surrounding ESFs and enable the targeted design and assessment of interventions for future HAs.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/AutoVis.png" alt="AutoVis preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/AutoVis.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>AutoVis: Enabling Mixed-Immersive Analysis of Automotive User Interface Interaction Studies</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Julian Britten, Alexander Häusele, Thilo Segschneider, Mark Colley, and Enrico Rukzio
                        </p>
                        
                        <p><strong>CHI '23</strong>: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-9')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/AutoVis.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/AutoVis.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/full/10.1145/3544548.3580760" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-9" style="display: none; padding-top: 5px; text-align: justify;">
                            Automotive user interface (AUI) evaluation becomes increasingly complex due to novel interaction modalities, driving automation, heterogeneous data, and dynamic environmental contexts. Immersive analytics may enable efficient explorations of the resulting multilayered interplay between humans, vehicles, and the environment. However, no such tool exists for the automotive domain. With AutoVis, we address this gap by combining a non-immersive desktop with a virtual reality view enabling mixed-immersive analysis of AUIs. We identify design requirements based on an analysis of AUI research and domain expert interviews (N=5). AutoVis supports analyzing passenger behavior, physiology, spatial interaction, and events in a replicated study environment using avatars, trajectories, and heatmaps. We apply context portals and driving-path events as automotive-specific visualizations. To validate AutoVis against real-world analysis tasks, we implemented a prototype, conducted heuristic walkthroughs using authentic data from a case study and public datasets, and leveraged a real vehicle in the analysis process.
                        </p>
                    </div>
                </div>



                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/auto-design-space.png" alt="In-vehicle design space preview" />
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>A Design Space for Human Sensor and Actuator Focused In-Vehicle Interaction Based on a Systematic Literature Review</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Mark Colley, and Enrico Rukzio
                        </p>
                        
                        <p><strong>IMWUT '22</strong>: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-8')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/auto-design-space.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3534617" class="acm">ACM</a> /
                                <a target="_blank" href="https://in-vehicle-interaction-design-space.onrender.com/" class="paper">Website</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-8" style="display: none; padding-top: 5px; text-align: justify;">
                            Automotive user interfaces constantly change due to increasing automation, novel features, additional applications, and user demands. While in-vehicle interaction can utilize numerous promising modalities, no existing overview includes an extensive set of human sensors and actuators and interaction locations throughout the vehicle interior. We conducted a systematic literature review of 327 publications leading to a design space for in-vehicle interaction that outlines existing and lack of work regarding input and output modalities, locations, and multimodal interaction. To investigate user acceptance of possible modalities and locations inferred from existing work and gaps unveiled in our design space, we conducted an online study (N=48). The study revealed users' general acceptance of novel modalities (e.g., brain or thermal activity) and interaction with locations other than the front (e.g., seat or table). Our work helps practitioners evaluate key design decisions, exploit trends, and explore new areas in the domain of in-vehicle interaction.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/swivr-car-seat.png" alt="SwiVR-Car-Seat preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/swivr-car-seat.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>SwiVR-Car-Seat: Exploring Vehicle Motion Effects on Interaction Quality in Virtual Reality Automated Driving Using a Motorized Swivel Seat</h2>
                        
                        <p> 
                            Mark Colley, <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Enrico Rukzio, and Jan Gugenheimer
                        </p>
                        
                        <p><strong>IMWUT '21</strong>: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-6')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/swivr-car-seat.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/swivr-car-seat.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3494968" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-6" style="display: none; padding-top: 5px; text-align: justify;">
                            Autonomous vehicles provide new input modalities to improve interaction with in-vehicle information systems. However, due to the road and driving conditions, the user input can be perturbed, resulting in reduced interaction quality. One challenge is assessing the vehicle motion effects on the interaction without an expensive high-fidelity simulator or a real vehicle. This work presents SwiVR-Car-Seat, a low-cost swivel seat to simulate vehicle motion using rotation. In an exploratory user study (N=18), participants sat in a virtual autonomous vehicle and performed interaction tasks using the input modalities touch, gesture, gaze, or speech. Results show that the simulation increased the perceived realism of vehicle motion in virtual reality and the feeling of presence. Task performance was not influenced uniformly across modalities; gesture and gaze were negatively affected while there was little impact on touch and speech. The findings can advise automotive user interface design to mitigate the adverse effects of vehicle motion on the interaction.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/the-social-engineer.png" alt="The Social Engineer preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/the-social-engineer.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="col-md-8" style="visibility: visible;">
                        <h2>The Social Engineer: An Immersive Virtual Reality Educational Game to Raise Social Engineering Awareness</h2>

                        <p>
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u> and Fabian Fischbach
                        </p>

                        <!-- Conference Name with Custom Badge Behind -->
                        <div style="position: relative; display: inline-block;">
                            <p style="position: relative; z-index: 2; margin: 0;">
                                <strong>CHI PLAY '20</strong>: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, <b><div class="award">Audience Choice Award</div></b>
                            </p>
                        </div>

                        <div class="row" style="padding: 0; margin-top: 10px; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-4')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/the-social-engineer.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/the-social-engineer.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3383668.3419917" class="acm">ACM</a>
                        </div>

                        <!-- Hidden Abstract -->
                        <p id="abstract-4" style="display: none; padding-top: 5px; text-align: justify;">
                            As system infrastructures are becoming more secure against technical attacks, it is more difficult for attackers to overcome them with technical means. Social engineering instead exploits the human factor of information security and can have a significant impact on organizations. The lack of awareness about social engineering favors the successful realization of social engineering attacks, as employees do not recognize them as such early enough, resulting in high costs for the affected company. Current training approaches and awareness courses are limited in their versatility and create little motivation for employees to deal with the topic. The high immersion of virtual reality can improve learning in this context. We created The Social Engineer, an immersive educational game in virtual reality, to raise awareness and to sensitize players about social engineering. The player impersonates a penetration tester and conducts security audits in a virtually simulated company. The game consists of a detailed game world containing three distinct missions that require the player to apply different social engineering attack methods. Our concept enables the game to be highly extensible and flexible regarding different playable scenarios and settings. The Social Engineer can potentially benefit companies as an immersive self-training tool for their employees, support security experts in teaching social engineering awareness as part of a comprehensive training course, and entertain interested individuals by leveraging fun and innovative gameplay mechanics.
                        </p>
                    </div>
                </div>


                <div class="row publication-entry">
                    <div class="col-md-4 text-center" style="visibility: visible;">
                        <div class="pub-media">
                            <img src="images/shARe.png" alt="ShARe preview" />
                            <video class="pub-video" muted playsinline preload="metadata" data-start="14">
                                <source src="data/videos/shARe.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="col-md-8" style="visibility: visible;">
                        <h2>ShARe: Enabling Co-Located Asymmetric Multi-User Interaction for Augmented Reality Head-Mounted Displays</h2>
                        
                        <p> 
                            <u><a target="_blank" href="https://www.pascal-jansen.github.io" style="text-decoration: none; margin-right: 0px;">Pascal Jansen</a></u>, Fabian Fischbach, Jan Gugenheimer, Evgeny Stemasov, Julian Frommel, and Enrico Rukzio
                        </p>
                        
                        <p><strong>UIST '20</strong>: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology</p>
                    
                        <div class="row" style="padding: 0; padding-left: 5px; margin-bottom: 10px;">
                                <!-- Abstract Button -->
                                <button onclick="toggleAbstract(this, 'abstract-3')" class="abstract-btn">Abstract</button> /
                                <a target="_blank" href="data/publications/shARe.pdf" class="paper">Paper</a> /
                                <a target="_blank" href="data/videos/shARe.mp4" class="video">Video</a> /
                                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3379337.3415843" class="acm">ACM</a>
                        </div>
                        
                        <!-- Hidden Abstract -->
                        <p id="abstract-3" style="display: none; padding-top: 5px; text-align: justify;">
                            Head-Mounted Displays (HMDs) are the dominant form of enabling Virtual Reality (VR) and Augmented Reality (AR) for personal use. One of the biggest challenges of HMDs is the exclusion of people in the vicinity, such as friends or family. While recent research on asymmetric interaction for VR HMDs has contributed to solving this problem in the VR domain, AR HMDs come with similar but also different problems, such as conflicting information in visualization through the HMD and projection. In this work, we propose ShARe, a modified AR HMD combined with a projector that can display augmented content onto planar surfaces to include the outside users (non-HMD users). To combat the challenge of conflicting visualization between augmented and projected content, ShARe visually aligns the content presented through the AR HMD with the projected content using an internal calibration procedure and a servo motor. Using marker tracking, non-HMD users are able to interact with the projected content using touch and gestures. To further explore the arising design space, we implemented three types of applications (collaborative game, competitive game, and external visualization). ShARe is a proof-of-concept system that showcases how AR HMDs can facilitate interaction with outside users to combat exclusion and instead foster rich, enjoyable social interactions.    
                        </p>
                    </div>
                </div>

<script>
document.querySelectorAll('.publication-entry').forEach(entry => {
  const video = entry.querySelector('.pub-video');
  if (!video) return;

  const startTime = parseFloat(video.dataset.start) || 0;

  function playFromStart() {
    try {
      video.currentTime = startTime;
    } catch (e) {
      // some browsers throw if not seekable yet
    }
    const p = video.play();
    if (p && p.catch) {
      p.catch(() => {
        // ignore autoplay errors
      });
    }
  }

  entry.addEventListener('mouseenter', () => {
    video.style.opacity = '1';

    if (video.readyState >= 2) {
      // metadata already loaded
      playFromStart();
    } else {
      // wait until we have metadata, then seek+play
      video.addEventListener('loadedmetadata', playFromStart, { once: true });
      video.load(); // ensure loading starts
    }
  });

  entry.addEventListener('mouseleave', () => {
    video.pause();
    try {
      video.currentTime = startTime;
    } catch (e) {}
    video.style.opacity = '0';
  });
});
</script>


                <div class="row">
                    <div class="col-md-12  " style="visibility: visible;  ">
                        <hr>
                        <h1 id="teaching">Teaching</h1>
                        <div class="row">
                            <div class="col-md-6">                  
                                <strong>Research Project in Human-Computer Interaction</strong>
                                <p>Co-organized year-long, interdisciplinary team projects on user-centered design, culminating in multiple peer-reviewed publications.</p>
                                <p><em>Fall 2021 - Spring 2025</em></p>

                                <strong>User Interface Software Technologies</strong>
                                <p>Developed course materials and delivered weekly hands-on lectures covering interactive systems, formal HCI methods, and notation.</p>
                                <p><em>Spring 2022 - Spring 2024</em></p>

                                <strong>Automotive User Interfaces and Interactive Vehicle Applications</strong>
                                <p>Led weekly practical sessions and one lecture on future mobility, teaching design and evaluation of in-vehicle interfaces.</p>
                                <p><em>Fall 2021 - Fall 2025</em></p>

                                <strong>Research Trends in Media Informatics</strong>
                                <p>Co-organized the course, mentored PhD students on PRISMA literature surveys, and assessed research proposals.</p>
                                <p><em>Fall 2021 - Fall 2024</em></p>
                            </div>

                            <div class="col-md-6">
                                <img src="images/study-supervision.png"
                                    alt="Student supervision"
                                    style="border-radius:12px;" />

                                <img src="images/team-supervision.png"
                                    alt="Team supervision"
                                    style="border-radius:12px;" />
                            </div>
                        </div>

                        <h4>Guest Lecturing</h4>
                        <p></p>
                        2025-02-13 "Personalization in Future Interfaces" <b> UCL Interaction Centre, London, UK</b>; in person; invited by <i> <a href="https://profiles.ucl.ac.uk/102233-mark-colley" target="_blank">Mark Colley</a> </i> <br/>
                        2026-03-04 "Personalization in Future Interfaces" <b> UCL Interaction Centre, London, UK</b>; in person; invited by <i> <a href="https://profiles.ucl.ac.uk/96949-george-chalhoub" target="_blank">George Chalhoub</a> </i> <br/>
                        <br>

                        <hr style="margin-top: 50px;">
                        
                        <h1 id="volunteering">Volunteering</h1>
                        Member of program committees:
                        <p></p>
                        <ul>
                            <li>CHI LBW '23 - '25</li>
                            <li>AutomotiveUI '24, '25</li>
                            <li>MuC '24, '25</li>
                            <li>CHIWORK '25, '26</li>
                            <li>CHI '26</li>
                        </ul>

                        <br>
                        <p></p>
                        Member of organizing committees:
                        <p></p>
                        <ul>
                            <li>Registration and Local Chair AutomotiveUI '23</li>
                            <li>Student Research Competition Chair MuC '26</li>
                        </ul>

                        <br>
                        <p></p>
                        Distinguished Reviewer Board:
                        <p></p>
                        <ul>
                            <li>ACM Transactions on Computer-Human Interaction (TOCHI)</li>
                        </ul>

                        <br>
                        <p></p>
                        Reviewer (Excerpt):
                        <p></p>
                        <ul>
                            <li>Conference:
                                <ul>
                                    <li>AutomotiveUI '21 - '25</li>
                                    <li>CHI '22 - '26</li>
                                    <li>DIS '22, '23</li>
                                    <li>IEEE VIS '23</li>
                                    <li>CSCW '24</li>
                                    <li>UIST '24, '25</li>
                                    <li>TEI '24, '25</li>
                                </ul>
                            </li>
                            
                            <li>Journal:
                                <ul>
                                    <li>IMWUT '22 - '25</li>
                                    <li>TVCG '22</li>
                                    <li>TRF '24</li>
                                    <li>BIT '24</li>
                                    <li>IEEE THMS '25</li>
                                    <li>IJHCS '25</li>
                                </ul>
                            </li>
                        </ul>

                        <br>
                        <p></p>
                        Special recognitions for reviews:
                        <p></p>
                        <ul>
                            <li>IMWUT 2022</li>
                            <li>ISS 2022</li>
                            <li>AutomotiveUI 2022</li>
                            <li>DIS 2023</li>
                            <li>IEEE VIS 2023</li>
                            <li>AutomotiveUI 2023</li>
                            <li>CHI 2024, <b>2x</b></li>
                            <li>CHI 2024 LBW</li>
                            <li>CSCW 2024</li>
                            <li>MuC 2024</li>
                            <li>UIST 2024</li>
                            <li>CHI 2025</li>
                            <li>IMWUT 2024</li>
                            <li>AutomotiveUI 2025</li>
                            <li>UIST 2025</li>
                            <li>IMWUT 2025</li>
                        </ul>
                        <p></p>
                        <p></p>
                        <br>

                        <hr style="margin-top: 50px;">
                        
                        <h1 id="entrepreneurship">Entrepreneurship</h1>
                        <div class="row">
                            <div class="col-md-9">                  
                                <h4>Co-Founder of <a href="https://zefwih.com/" target="_blank">Zefwih</a></h4>
                                <p>Consulting on digitalization and future multimedia. I lead business and research strategy while contributing to the development of desktop, mobile, and VR user-centered applications for commercial, cultural, and research contexts.</p>
                                <p>Created a serious game to guard against social engineering attacks, nominated for the German Computer Game Awards and finalist at the Games for Change Awards: <a href="https://store.steampowered.com/app/2746510/The_Social_Engineer/" target="_blank">The Social Engineer</a> (available on Steam)</p>
                            </div>

                            <div class="col-md-3 zefwih-img">
                                <img src="images/zefwih-banner.png" alt="Student Banner" />
                            </div>
                        </div>

                        <hr>
                        <br />
                    </div>
                </div>
            </div>
        </section>
        <!--  End Publication Section  -->

        <footer style="text-align:center; margin-bottom: 35px; font-size:1.5rem;">
            &copy; 2026&nbsp;Pascal&nbsp;Jansen&nbsp;&nbsp;|&nbsp;
            <a href="impressum.html" target="_blank">Imprint</a>&nbsp;|&nbsp;
            <a href="privacy.html" target="_blank">Privacy&nbsp;Policy</a>
        </footer>

        <!-- Banner styles -->
        <style>
        #cookie-banner{
            position:fixed;bottom:0;left:0;right:0;
            background:#eee;padding:8px 10px;font-size:.8rem;
            box-shadow:0 -1px 4px rgba(0,0,0,.2);z-index:9999;
            text-align:center;
        }
        #cookie-banner button{
            margin-left:.5rem;padding:2px 6px;border:0;border-radius:3px;
            background:#007bff;color:#fff;cursor:pointer;font-size:.8rem;
        }
        #cookie-banner a{color:#007bff;text-decoration:underline;}
        </style>

        <!-- Banner markup -->
        <div id="cookie-banner">
        This site uses cookies for Google&nbsp;Analytics. 
        <a href="/privacy.html">Details</a>
        <button id="cookie-close">OK</button>
        </div>

        <!-- Banner script -->
        <script>
        (function(){
        const banner = document.getElementById('cookie-banner');
        const close  = document.getElementById('cookie-close');
        if(localStorage.getItem('cookie_notice')==='dismissed'){ banner.remove(); }
        close.addEventListener('click', ()=>{
            localStorage.setItem('cookie_notice','dismissed');
            banner.remove();
        });
        })();
        </script>

        <script>
        document.addEventListener('DOMContentLoaded', function () {
        const sidePanel    = document.getElementById('side-profile-panel');
        const bioSection   = document.querySelector('.bio');
        const pubContainer = document.querySelector('#publication .container');

        function getPanelWidth() {
            if (!sidePanel) return 0;

            const cs = window.getComputedStyle(sidePanel);
            if (cs.display === 'none') {
            const prev = {
                display: sidePanel.style.display,
                visibility: sidePanel.style.visibility,
                position: sidePanel.style.position,
                left: sidePanel.style.left,
                top: sidePanel.style.top
            };

            sidePanel.style.display = 'block';
            sidePanel.style.visibility = 'hidden';
            sidePanel.style.position = 'fixed';
            sidePanel.style.left = '-9999px';
            sidePanel.style.top = '0';

            const w = sidePanel.getBoundingClientRect().width || 0;

            Object.assign(sidePanel.style, prev);
            return w;
            }

            return sidePanel.getBoundingClientRect().width || 0;
        }

        function positionSidePanel() {
            if (!sidePanel || !pubContainer) return;

            const rect    = pubContainer.getBoundingClientRect();
            const scrollX = window.pageXOffset || document.documentElement.scrollLeft;
            const panelW  = getPanelWidth();

            const containerLeft = rect.left + scrollX;

            /* RIGHT edge of panel aligns with LEFT edge of publication container */
            // sidePanel.style.left = (containerLeft - panelW - 20) + 'px';

            /* FULL viewport height, no offset */
            sidePanel.style.top    = '0';
            sidePanel.style.height = '100vh';
        }

        function toggleSidePanel() {
            if (!sidePanel || !bioSection) return;

            const triggerY = bioSection.offsetHeight;

            if (window.scrollY > triggerY) {
            sidePanel.classList.add('visible');
            positionSidePanel();
            } else {
            sidePanel.classList.remove('visible');
            }
        }

        window.addEventListener('scroll', toggleSidePanel);
        window.addEventListener('resize', positionSidePanel);

        positionSidePanel();
        toggleSidePanel();
        });
        </script>
    </body>
</html>
